{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "00SIPURUh4xH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00SIPURUh4xH",
        "outputId": "5302bd1c-617c-47e8-e7df-ae13b64a7931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "PCLWFE1bQxjx",
      "metadata": {
        "id": "PCLWFE1bQxjx"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/drive/MyDrive/langgraph-code-assistant/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "sBYVvPZDiUWu",
      "metadata": {
        "id": "sBYVvPZDiUWu"
      },
      "outputs": [],
      "source": [
        "!wget http://www.comp.nus.edu.sg/~release/codeflaws/codeflaws.tar.gz\n",
        "!cp /content/codeflaws.tar.gz   /content/drive/MyDrive/langgraph-code-assistant/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "u-EYdSb3PGrx",
      "metadata": {
        "id": "u-EYdSb3PGrx"
      },
      "outputs": [],
      "source": [
        "!tar xf ./codeflaws.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "951cdf09",
      "metadata": {
        "id": "951cdf09"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install -U langchain langchain_openai langgraph langchain_community\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9a44dadb",
      "metadata": {
        "id": "9a44dadb"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Suresoft-GLaDOS/SBFL\n",
        "%cd SBFL\n",
        "!pip install -r requirements.txt\n",
        "!pip install setuptools\n",
        "!python setup.py install\n",
        "%cd ../\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "64de2fe1",
      "metadata": {
        "id": "64de2fe1"
      },
      "outputs": [],
      "source": [
        "import SBFL.sbfl.utils as sbfl_utils\n",
        "import SBFL.sbfl.base as sbfl_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "941ee4a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "941ee4a5",
        "outputId": "6405dc8b-b6ab-4cd2-e7c3-6ec82071dd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.         0.57735027 1.        ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    X: coverage data\n",
        "    y: test results\n",
        "    \"\"\"\n",
        "    X = np.array([\n",
        "        [1,0,1], # coverage of test t0\n",
        "        [1,0,1], # coverage of test t1\n",
        "        [1,1,1]  # coverage of test t2\n",
        "    ], dtype=bool)\n",
        "\n",
        "    y = np.array([\n",
        "        0, # t0: PASS\n",
        "        0, # t1: FAIL\n",
        "        0  # t2: PASS\n",
        "    ], dtype=bool)\n",
        "\n",
        "    \"\"\"\n",
        "    Calculate the suspiciousness scores\n",
        "    \"\"\"\n",
        "    sbfl = sbfl_base.SBFL(formula='Ochiai')\n",
        "    print(sbfl.fit_predict(X, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d9332308",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9332308",
        "outputId": "93c56f40-ecfc-4e33-fa79-9bf2e0c3044b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from pprint import pprint\n",
        "import collections\n",
        "import subprocess\n",
        "import itertools\n",
        "import shutil\n",
        "import random\n",
        "import json\n",
        "import uuid\n",
        "import tqdm\n",
        "import glob\n",
        "import time\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "ce4cf24c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce4cf24c",
        "outputId": "072c4c03-4af7-4baa-a738-476189e09229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta-llama/open-router-llama-3.1-405b-instruct:free\n",
            "open-router-llama-3.1-405b-instruct:free\n"
          ]
        }
      ],
      "source": [
        "APPLY_SBFL = False\n",
        "WITHOUT_TESTCASES_EXEC = True\n",
        "COUNT_RETRY_OPENROUTER = 3\n",
        "# LLM_MODEL_NAME = \"meta-llama/open-router-llama-3.1-70b-instruct:free\"\n",
        "# LLM_MODEL_NAME = \"meta-llama/open-router-llama-3.2-90b-vision-instruct:free\"\n",
        "LLM_MODEL_NAME = \"meta-llama/open-router-llama-3.1-405b-instruct:free\"\n",
        "LLM_MODEL_NAME = (LLM_MODEL_NAME) + (\"-with-sbfl\" if APPLY_SBFL else \"\")\n",
        "\n",
        "\n",
        "LLM_MODEL_NAME_SPLIT = LLM_MODEL_NAME.split('/')[-1]\n",
        "STORE_GRAPH_IN_MEMORY = False\n",
        "USE_OLLAMA = True\n",
        "RUN_ON_COLAB = True\n",
        "RUN_ON_KAGGLE = False\n",
        "RUN_ON_WINDOWS = False\n",
        "CHECK_BEFORE_ASK = True\n",
        "if RUN_ON_KAGGLE:\n",
        "    PATH_FOR_RUNNING = '/kaggle/working'\n",
        "elif RUN_ON_COLAB:\n",
        "    PATH_FOR_RUNNING = '/content/drive/MyDrive/langgraph-code-assistant'\n",
        "else:\n",
        "    PATH_FOR_RUNNING = '.'\n",
        "\n",
        "print(LLM_MODEL_NAME)\n",
        "print(LLM_MODEL_NAME_SPLIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "847e4770",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "847e4770",
        "outputId": "7c165ba5-f61c-4b23-cf6a-118ffa7e1ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No module named 'langgraph.checkpoint.sqlite'\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, TypedDict, Optional, List, Set\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "try:\n",
        "    from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    pass\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    llm_model_name: Optional[str]\n",
        "    code_file_path: Optional[str]\n",
        "    test_case_paths: List[str]\n",
        "    fail_test_cases: List[dict]\n",
        "    pass_test_cases: List[dict]\n",
        "    log_execution: Set[str]\n",
        "    code_have_error: Optional[bool]\n",
        "    next_node: Optional[str]\n",
        "    max_try_count: Optional[int]\n",
        "    try_count: Optional[int]\n",
        "    messages: List[tuple]\n",
        "    initial_failed_test_cases_count: Optional[int]\n",
        "    list_failed_test_cases_count: List[int]\n",
        "    initial_code_have_error: Optional[bool]\n",
        "    generated_code: Optional[str]\n",
        "    llm_tokens: Optional[int]\n",
        "    apply_sbfl: Optional[bool]\n",
        "    sbfl_formula: Optional[str]\n",
        "    sbfl_likelihood: Optional[float]\n",
        "    sbfl_result: Optional[str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e71c1f4d",
      "metadata": {
        "id": "e71c1f4d"
      },
      "outputs": [],
      "source": [
        "def read_specific_file(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        content_file = f.read()\n",
        "    return content_file\n",
        "\n",
        "\n",
        "def write_specific_file(path, content):\n",
        "    with open(path, 'w') as f:\n",
        "        f.write(content)\n",
        "\n",
        "\n",
        "def delete_specific_type_in_dir(directory_path = PATH_FOR_RUNNING, #'/kaggle/working',\n",
        "                                file_extensions = ['*.out', '*.gcno', '*.gcda']):\n",
        "            # Specify the directory\n",
        "            directory_path = directory_path\n",
        "            # Specify the file types\n",
        "            file_extensions = file_extensions\n",
        "            # Loop over each file type pattern\n",
        "            for file_extension in file_extensions:\n",
        "                # Construct the full path pattern\n",
        "                file_pattern = os.path.join(directory_path, file_extension)\n",
        "                # Find all files matching the pattern\n",
        "                files_to_remove = glob.glob(file_pattern)\n",
        "                # Remove each file\n",
        "                for file_path in files_to_remove:\n",
        "                    try:\n",
        "                        os.remove(file_path)\n",
        "                    except Exception as e:\n",
        "                        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "6a3fec69",
      "metadata": {
        "id": "6a3fec69"
      },
      "outputs": [],
      "source": [
        "def extract_line_num_c_gcov_file(gcov_file):\n",
        "    dct_line_code = {}\n",
        "    try:\n",
        "        # Read gcov_file and extract line_number & code\n",
        "        with open(gcov_file, 'r') as gcov_fl:\n",
        "            for line in gcov_fl:\n",
        "                l_split = line.split(':')\n",
        "                if len(l_split) > 1:\n",
        "                    # parse the line\n",
        "                    hits = l_split[0].strip()\n",
        "                    line_num = int(l_split[1].strip())\n",
        "                    code = ':'.join(l_split[2:]).strip()\n",
        "                    if line_num > 0 and code != '':\n",
        "                        dct_line_code[line_num] = code\n",
        "\n",
        "    except StopIteration:\n",
        "        print('We can not find any gcov_file.')\n",
        "        raise ValueError('We can not find any gcov_file.')\n",
        "\n",
        "    return dct_line_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "2162f9ae",
      "metadata": {
        "id": "2162f9ae"
      },
      "outputs": [],
      "source": [
        "def compute_error_suspicious(dct_info, formulas=['Ochiai']):\n",
        "\n",
        "    assert 'Gcov_Dirs' in dct_info\n",
        "    assert 'Failed_Test_Cases' in dct_info\n",
        "\n",
        "    dct_gcov_dirs = dct_info['Gcov_Dirs']\n",
        "    lst_failed_test_cases = dct_info['Failed_Test_Cases']\n",
        "\n",
        "    gcov_files = {test:[] for test in dct_gcov_dirs}\n",
        "    for test in dct_gcov_dirs:\n",
        "        for path in os.listdir(dct_gcov_dirs[test]):\n",
        "            if path.endswith('.gcov'):\n",
        "                gcov_files[test].append(os.path.join(dct_gcov_dirs[test], path))\n",
        "\n",
        "    dct_weight_suspicious_line = dict.fromkeys(formulas, {})\n",
        "    if len(lst_failed_test_cases) > 0 :\n",
        "        cov_df = sbfl_utils.gcov_files_to_frame(gcov_files, only_covered=True, verbose=False)\n",
        "\n",
        "        for formula in formulas:\n",
        "            # We can change formula to 'Ochiai' or 'Tarantula' or 'Jaccard' or 'Kulczynski2' or ...\n",
        "            score_df = sbfl_utils.get_sbfl_scores_from_frame(cov_df,\n",
        "                                                            failing_tests=lst_failed_test_cases,\n",
        "                                                            sbfl = sbfl_base.SBFL(formula)\n",
        "                                                            )\n",
        "            score_df = score_df.reset_index()\n",
        "            dct_weight_suspicious_line[formula] = dict(zip(score_df['line'], score_df['score']))\n",
        "\n",
        "    return dct_weight_suspicious_line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "85f7e20e",
      "metadata": {
        "id": "85f7e20e"
      },
      "outputs": [],
      "source": [
        "def check_code_with_test_cases(state):\n",
        "    fail_test_cases = []\n",
        "    pass_test_cases = []\n",
        "    log_execution = set()\n",
        "    try:\n",
        "        code_file_path = state.get('code_file_path', '')\n",
        "        test_case_paths = state.get('test_case_paths', [])\n",
        "        c_file_name = code_file_path.rsplit('/', 1)[-1][:-2]\n",
        "        if not code_file_path or not test_case_paths:\n",
        "            log_execution.add(\"Invalid code file path or test case paths.\")\n",
        "            return {\n",
        "                'log_execution': log_execution,\n",
        "                'code_have_error': None,\n",
        "                'fail_test_cases': fail_test_cases,\n",
        "                'pass_test_cases': pass_test_cases,\n",
        "                'initial_failed_test_cases_count': None,\n",
        "                'initial_code_have_error': None,\n",
        "                'sbfl_result': '',\n",
        "                'list_failed_test_cases_count': state.get('list_failed_test_cases_count', []),\n",
        "            }\n",
        "        # Define a 'dict' to store all gcov's directories\n",
        "        dct_gcov_dirs = {}\n",
        "        # Define a 'list' to store failed test_cases\n",
        "        lst_failed_test_cases = []\n",
        "        # Call to extract line of code\n",
        "        call_extract_line_num_c_gcov = True\n",
        "        # Apply and use SBFL\n",
        "        apply_sbfl = state.get('apply_sbfl', False)\n",
        "        sbfl_result = ''\n",
        "        # dct_line_code from gcov\n",
        "        dct_line_code = {}\n",
        "        for test_case_path in test_case_paths:\n",
        "            if 'input' in test_case_path:\n",
        "                input_file_test = test_case_path\n",
        "                output_file_test = test_case_path.replace('input', 'output')\n",
        "                # Read input/output test_case\n",
        "                content_in_file_test  = read_specific_file(path = input_file_test)\n",
        "                content_out_file_test = read_specific_file(path = output_file_test)\n",
        "                # Compile c_file\n",
        "                # Run the gcc command and capture the output (including warnings)\n",
        "                command = f'gcc -fprofile-arcs -ftest-coverage -fstack-protector-all {code_file_path} -o {c_file_name}.out -lm 2>&1'\n",
        "                result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "                # Store the warnings (and other output) in a variable\n",
        "                warnings_output = result.stdout\n",
        "                if warnings_output:\n",
        "                    log_execution.add(warnings_output)\n",
        "                # Run c_file and input test case\n",
        "                output_run_exe = \"Error\"\n",
        "                try:\n",
        "                    # Use timeout to terminate execution of program\n",
        "                    # If the program doesn't exit (for example have infinite loop)\n",
        "                    if RUN_ON_WINDOWS:\n",
        "                        output_run_exe =  os.popen(f'{c_file_name}.out < {input_file_test}').read()\n",
        "                    else:\n",
        "                        output_run_exe =  os.popen(f'timeout 2s ./{c_file_name}.out < {input_file_test}').read()\n",
        "\n",
        "\n",
        "                    if apply_sbfl:\n",
        "                        # Rename example.out-example.gcno -> example.gcno\n",
        "                        for f in os.listdir('.'):\n",
        "                            if len(f.split('.out-')) > 1:\n",
        "                                os.rename(f, f.split('.out-')[-1])\n",
        "                        # Copy *.c in the path that *.gcda & *.gcno exist\n",
        "                        # That we can run command : 'gcov *.c'\n",
        "                        shutil.copy(code_file_path, '.')\n",
        "                        # Extract name of test_case with 'rsplit()'\n",
        "                        test_case_name = input_file_test.rsplit('/', 1)[-1]\n",
        "                        # Run gcov on *.gcov.c\n",
        "                        os.system(f\"gcov {c_file_name}.c\")\n",
        "                        # Path of directory for store information\n",
        "                        dir_store_info = f'./{c_file_name}' #f'{PATH_FOR_RUNNING}/{c_file_name}'\n",
        "                        # Check all tmp files that created or NOT (gcov is valid or NOT)\n",
        "                        if all(f\"{c_file_name}{typ}\" in os.listdir('.') for typ in ['.c', '.gcno', '.gcda', '.c.gcov']):\n",
        "                            # Create directory for saving different *.gcov.c to use later\n",
        "                            directory = f'{dir_store_info}/{test_case_name}'\n",
        "                            if not os.path.exists(directory):\n",
        "                                os.makedirs(directory)\n",
        "                            # extract_line_num_c_gcov_file\n",
        "                            try:\n",
        "                                if call_extract_line_num_c_gcov:\n",
        "                                    dct_line_code = extract_line_num_c_gcov_file(gcov_file=f\"{c_file_name}.c.gcov\")\n",
        "                                    if dct_line_code != {}:\n",
        "                                        call_extract_line_num_c_gcov = False\n",
        "                            except Exception as e:\n",
        "                                call_extract_line_num_c_gcov = True\n",
        "                            # Move and store *.gcov result to created directory\n",
        "                            shutil.move(f\"{c_file_name}.c.gcov\", f\"{directory}/{c_file_name}.c.gcov\")\n",
        "                            # Store the directory of gcov result\n",
        "                            dct_gcov_dirs[test_case_name] = directory\n",
        "\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    log_execution.add(repr(e))\n",
        "                    output_run_exe = 'Error'\n",
        "                # Compare True Vs. Execute answer\n",
        "                res_compare = (output_run_exe.strip() == content_out_file_test.strip())\n",
        "                # Define a 'dict' to store the information of c_file's execution and test_cases\n",
        "                dct_execute_info = {\n",
        "                    'Input_Data'  : content_in_file_test.strip(),\n",
        "                    'True_Ans'    : content_out_file_test.strip(),\n",
        "                    'Exec_Ans'    : output_run_exe.strip(),\n",
        "                    'Equal_Ans'   : res_compare\n",
        "                }\n",
        "                if res_compare:\n",
        "                    pass_test_cases.append(dct_execute_info)\n",
        "                else:\n",
        "                    fail_test_cases.append(dct_execute_info)\n",
        "\n",
        "                    if apply_sbfl:\n",
        "                        # Check if gcov exist in dirs then append test_case_name\n",
        "                        # Maybe we have error and don't havr gcov\n",
        "                        if test_case_name in dct_gcov_dirs:\n",
        "                            lst_failed_test_cases.append(test_case_name)\n",
        "\n",
        "                # Delete all files with the specified extensions in the given directory.\n",
        "                delete_specific_type_in_dir(\n",
        "                    directory_path = '.', #PATH_FOR_RUNNING, #'/kaggle/working',\n",
        "                    file_extensions = ['*.out', '*.gcno', '*.gcda', '*.c', '*.gcov'])\n",
        "\n",
        "        if apply_sbfl:\n",
        "            dct_info = {\n",
        "                'Gcov_Dirs': dct_gcov_dirs,\n",
        "                'Failed_Test_Cases': lst_failed_test_cases,\n",
        "            }\n",
        "\n",
        "            dct_score_code = {}\n",
        "            formula = state.get(\"sbfl_formula\", \"Ochiai\")\n",
        "            try:\n",
        "                dct_score_code = compute_error_suspicious(dct_info, formulas=[formula])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "            # remove store gcov result\n",
        "            try:\n",
        "                shutil.rmtree(dir_store_info)\n",
        "            except FileNotFoundError:\n",
        "                print(f\"The folder does not exist: {dir_store_info}\")\n",
        "            except PermissionError:\n",
        "                print(f\"Permission denied: {dir_store_info}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "\n",
        "            dct_line_code_score = {}\n",
        "            for key_line in dct_score_code.get(formula, {}):\n",
        "                    dct_line_code_score[key_line] = {\n",
        "                        'code': dct_line_code.get(key_line, ''),\n",
        "                        'score': dct_score_code.get(formula, {}).get(key_line, 0)\n",
        "                    }\n",
        "\n",
        "            sorted_dct_line_code_score = sorted(dct_line_code_score.items(), key=lambda x: x[1]['score'])[::-1]\n",
        "            filter_len = int( state.get(\"sbfl_likelihood\", 0.5) * len(sorted_dct_line_code_score))\n",
        "            sbfl_result = '\\n'.join(f\"{line} : {dct['code']}\" for line, dct in sorted_dct_line_code_score[:filter_len])\n",
        "\n",
        "\n",
        "        initial_failed_test_cases_count = state.get('initial_failed_test_cases_count', len(fail_test_cases))\n",
        "        initial_code_have_error = state.get('initial_code_have_error', len(fail_test_cases)>0)\n",
        "        list_failed_test_cases_count = state.get('list_failed_test_cases_count', [])\n",
        "        list_failed_test_cases_count.append(len(fail_test_cases))\n",
        "\n",
        "        return {\n",
        "            'list_failed_test_cases_count': list_failed_test_cases_count,\n",
        "            'fail_test_cases': fail_test_cases,\n",
        "            'pass_test_cases': pass_test_cases,\n",
        "            'log_execution': log_execution,\n",
        "            'code_have_error': (False if not fail_test_cases else True),\n",
        "            'initial_failed_test_cases_count': initial_failed_test_cases_count,\n",
        "            'initial_code_have_error': initial_code_have_error,\n",
        "            'sbfl_result': sbfl_result,\n",
        "        }\n",
        "    except Exception as e:\n",
        "        log_execution.add(repr(e))\n",
        "        return {'log_execution': log_execution,\n",
        "                'code_have_error': None,\n",
        "                'fail_test_cases': fail_test_cases,\n",
        "                'pass_test_cases': pass_test_cases,\n",
        "                'initial_failed_test_cases_count': None,\n",
        "                'initial_code_have_error': None,\n",
        "                'sbfl_result': '',\n",
        "                'list_failed_test_cases_count': state.get('list_failed_test_cases_count', []),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "kWCTonwIcNwP",
      "metadata": {
        "id": "kWCTonwIcNwP"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_models import ChatOpenAI\n",
        "\n",
        "class ChatOpenRouter(ChatOpenAI):\n",
        "    openai_api_base: str\n",
        "    openai_api_key: str\n",
        "    model_name: str\n",
        "\n",
        "    def __init__(self,\n",
        "                 model_name: str,\n",
        "                 openai_api_key: str = '',\n",
        "                 openai_api_base: str = \"https://openrouter.ai/api/v1\",\n",
        "                 **kwargs):\n",
        "        super().__init__(openai_api_base=openai_api_base,\n",
        "                         openai_api_key=openai_api_key,\n",
        "                         model_name=model_name, **kwargs)\n",
        "\n",
        "        print(openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "V-4CAxpDr5bq",
      "metadata": {
        "id": "V-4CAxpDr5bq"
      },
      "outputs": [],
      "source": [
        "from itertools import cycle\n",
        "\n",
        "class GetAPIOpenRouter():\n",
        "    def __init__(self):\n",
        "        # List of available API keys\n",
        "        api_keys = [\n",
        "            \"api_keys_1\",\n",
        "            \"api_keys_2\",\n",
        "        ]\n",
        "\n",
        "        self.iter_api_keys = cycle(api_keys[::-1])\n",
        "        print(\"Count APIOpenRouter : \", len(api_keys))\n",
        "\n",
        "\n",
        "    def get_open_router_api_key(self):\n",
        "        openai_api_key = next(self.iter_api_keys)\n",
        "        return openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "LFW-P8SZLrEV",
      "metadata": {
        "id": "LFW-P8SZLrEV"
      },
      "outputs": [],
      "source": [
        "def test_open_router():\n",
        "    open_router_model_name = (\n",
        "        LLM_MODEL_NAME.replace(\"open-router-\", \"\").replace(\"-with-sbfl\", \"\")\n",
        "        if APPLY_SBFL\n",
        "        else\n",
        "        LLM_MODEL_NAME.replace(\"open-router-\", \"\")\n",
        "    )\n",
        "    cnt_retry = COUNT_RETRY_OPENROUTER\n",
        "    while cnt_retry:\n",
        "        try:\n",
        "            openai_api_key = get_api_open_router.get_open_router_api_key()\n",
        "            print(f\"Try {cnt_retry}, With {open_router_model_name}, By {openai_api_key}\")\n",
        "            llm = ChatOpenRouter(\n",
        "                model_name=open_router_model_name,\n",
        "                openai_api_key=openai_api_key,\n",
        "            )\n",
        "            prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
        "            openrouter_chain = prompt | llm\n",
        "            print(openrouter_chain.invoke({\"topic\": \"banana\"}))\n",
        "            return\n",
        "        except Exception as e:\n",
        "            if cnt_retry == 1:\n",
        "                raise ValueError(e)\n",
        "            time.sleep(10)\n",
        "            cnt_retry -= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "RBY0PS7pP_GZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBY0PS7pP_GZ",
        "outputId": "932440ca-2739-4e2d-e857-2f066bc55a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count APIOpenRouter :  2\n",
            "Try 3, With meta-llama/llama-3.1-405b-instruct:free, By api_keys_2\n",
            "api_keys_2\n",
            "Try 2, With meta-llama/llama-3.1-405b-instruct:free, By api_keys_1\n",
            "api_keys_1\n",
            "Try 1, With meta-llama/llama-3.1-405b-instruct:free, By api_keys_2\n",
            "api_keys_2\n",
            "Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}\n"
          ]
        }
      ],
      "source": [
        "get_api_open_router = GetAPIOpenRouter()\n",
        "\n",
        "try:\n",
        "    test_open_router()\n",
        "except Exception as e:\n",
        "    if \"'NoneType' object is not iterable\" in repr(e):\n",
        "        print(\"open-router API is not reachable\")\n",
        "    print(e)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "cd76465c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd76465c",
        "outputId": "8457020c-0900-4fe3-b9bf-d7a44622e482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count APIOpenRouter :  2\n"
          ]
        }
      ],
      "source": [
        "get_api_open_router = GetAPIOpenRouter()\n",
        "\n",
        "\n",
        "SYSTEM_PROMPT_REPAIR_FAULTY_CODE = \"\"\"You are a coding assistant. \\\n",
        "You have access to code and the results of its successful and unsuccessful executions on a number of test cases. \\\n",
        "Based on the results you observe, modify the faulty code so that all the successful test cases remain successful and the unsuccessful test cases produce results similar to the expected output, making the code error-free. \\\n",
        "Use the above unsuccessful and successful executions on a number of test cases to repair the faulty code.\n",
        "You should provide only the error-free code in the block without any explanation, like this: \\n\n",
        "```c\n",
        "#include <stdio.h>\n",
        "int main(int argc, char *argv[])\n",
        "{{\n",
        "    return 0;\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "SYSTEM_PROMPT_REPAIR_FAULTY_CODE_WITHOUT_TESTCASES_EXEC = \"\"\"You are a coding assistant with access to code. \\\n",
        "Your task is to identify and fix errors in the provided code. \\\n",
        "Respond with only the corrected, error-free code formatted within a code block, without any explanation or additional comments, like this: \\n\n",
        "```c\n",
        "#include <stdio.h>\n",
        "int main(int argc, char *argv[])\n",
        "{{\n",
        "    return 0;\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "USER_PROMPT_REPAIR_FAULTY_CODE_WITHOUT_SBFL = \"\"\"Here is the faulty code you need to repair:\n",
        "\\n --- \\n ```c\\n{code}``` \\n --- \\n\n",
        "Below are all available unsuccessful executions:\n",
        "\\n --- \\n {fail_test_cases} \\n --- \\n\n",
        "Below are all available successful executions:\n",
        "\\n --- \\n {pass_test_cases} \\n --- \\n\n",
        "Below are all available log of compiler and executions:\n",
        "\\n --- \\n {log_execution} \\n --- \\n\n",
        "Use the above unsuccessful and successful executions on a number of test cases to repair the faulty code.\n",
        "Please provide only the error-free code in the block without any explanation, like this: \\n\n",
        "```c\n",
        "#include <stdio.h>\n",
        "int main(int argc, char *argv[])\n",
        "{{\n",
        "    return 0;\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "USER_PROMPT_REPAIR_FAULTY_CODE_WITH_SBFL = \"\"\"The following faulty code contains errors identified using Spectrum-Based Fault Localization (SBFL) techniques. These techniques compute the likelihood of faults in specific lines of code based on statistical methods, pinpointing the most suspicious lines. Below is the code you need to repair:\n",
        "\\n --- \\n ```c\\n{code}``` \\n --- \\n\n",
        "Below are the SBFL results showing suspicious lines and their fault likelihood scores:\n",
        "\\n --- \\n {sbfl_results} \\n --- \\n\n",
        "Below are all available unsuccessful executions:\n",
        "\\n --- \\n {fail_test_cases} \\n --- \\n\n",
        "Below are all available successful executions:\n",
        "\\n --- \\n {pass_test_cases} \\n --- \\n\n",
        "Below are all available logs of compiler and executions:\n",
        "\\n --- \\n {log_execution} \\n --- \\n\n",
        "Utilize the above information, particularly the SBFL results and the unsuccessful/successful executions, to identify and repair the faulty code.\n",
        "Please provide only the error-free code in the following format, without any explanation:\n",
        "```c\n",
        "#include <stdio.h>\n",
        "int main(int argc, char *argv[])\n",
        "{{\n",
        "    return 0;\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "USER_PROMPT_REPAIR_FAULTY_CODE_WITHOUT_SBFL_WITHOUT_TESTCASES_EXEC = \"\"\"Here is the faulty code you need to repair:\n",
        "\\n --- \\n ```c\\n{code}``` \\n --- \\n\n",
        "Please provide only the error-free code in the block without any explanation, like this: \\n\n",
        "```c\n",
        "#include <stdio.h>\n",
        "int main(int argc, char *argv[])\n",
        "{{\n",
        "    return 0;\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "def test_cases_execution_to_str(lst_dct):\n",
        "    result = \"\"\n",
        "    for dct in lst_dct:\n",
        "        result += str(dct) + \"\\n\"\n",
        "    return result\n",
        "\n",
        "\n",
        "def repair_faulty_code(state):\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "            (\n",
        "                \"system\",\n",
        "                SYSTEM_PROMPT_REPAIR_FAULTY_CODE\n",
        "            ),\n",
        "            (\n",
        "                \"placeholder\",\n",
        "                \"{messages}\"\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    messages = state[\"messages\"]\n",
        "    lst_dct_fail_test_cases = state.get('fail_test_cases')\n",
        "    lst_dct_pass_test_cases = state.get('pass_test_cases')\n",
        "\n",
        "    if WITHOUT_TESTCASES_EXEC:\n",
        "        # Only pass faulty code and ask to fix code\n",
        "        USER_PROMPT_REPAIR_FAULTY_CODE = (\n",
        "            USER_PROMPT_REPAIR_FAULTY_CODE_WITHOUT_SBFL_WITHOUT_TESTCASES_EXEC.format(**{\n",
        "                'code': read_specific_file(path=state.get('code_file_path')),\n",
        "            })\n",
        "        )\n",
        "    else:\n",
        "        USER_PROMPT_REPAIR_FAULTY_CODE = (\n",
        "            USER_PROMPT_REPAIR_FAULTY_CODE_WITHOUT_SBFL.format(**{\n",
        "                'code': read_specific_file(path=state.get('code_file_path')),\n",
        "                'fail_test_cases': test_cases_execution_to_str(lst_dct=lst_dct_fail_test_cases),\n",
        "                'pass_test_cases': test_cases_execution_to_str(lst_dct=lst_dct_pass_test_cases),\n",
        "                'log_execution' : '\\n'.join(state.get('log_execution', ''))\n",
        "            })\n",
        "        )\n",
        "        if state.get(\"apply_sbfl\", False) == True:\n",
        "            USER_PROMPT_REPAIR_FAULTY_CODE = (\n",
        "                    USER_PROMPT_REPAIR_FAULTY_CODE_WITH_SBFL.format(**{\n",
        "                        'code': read_specific_file(path=state.get('code_file_path')),\n",
        "                        'sbfl_results': state.get('sbfl_result', ''),\n",
        "                        'fail_test_cases': test_cases_execution_to_str(lst_dct=lst_dct_fail_test_cases),\n",
        "                        'pass_test_cases': test_cases_execution_to_str(lst_dct=lst_dct_pass_test_cases),\n",
        "                        'log_execution' : '\\n'.join(state.get('log_execution', ''))\n",
        "                    })\n",
        "        )\n",
        "    messages += [\n",
        "        (\n",
        "            \"user\",\n",
        "            USER_PROMPT_REPAIR_FAULTY_CODE\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    LLM_MODEL_NAME = state['llm_model_name']\n",
        "    LLM_MODEL_NAME_SPLIT = LLM_MODEL_NAME.split('/')[-1] + (\"-wo-testcases-exec\" if WITHOUT_TESTCASES_EXEC else \"\")\n",
        "    open_router_model_name = (\n",
        "        LLM_MODEL_NAME.replace(\"open-router-\", \"\").replace(\"-with-sbfl\", \"\")\n",
        "        if APPLY_SBFL\n",
        "        else\n",
        "        LLM_MODEL_NAME.replace(\"open-router-\", \"\")\n",
        "    )\n",
        "\n",
        "    cnt_retry = COUNT_RETRY_OPENROUTER\n",
        "    while cnt_retry:\n",
        "        try:\n",
        "            # Randomly select an API key\n",
        "            openai_api_key = get_api_open_router.get_open_router_api_key()\n",
        "            print(f\"Try {cnt_retry}, With {open_router_model_name}, By {openai_api_key}\")\n",
        "            llm = ChatOpenRouter(\n",
        "                model_name=open_router_model_name,\n",
        "                openai_api_key=openai_api_key\n",
        "            )\n",
        "            chain = (prompt | llm)\n",
        "            result = chain.invoke({'messages' : messages})\n",
        "            # Because we don't get an error\n",
        "            cnt_retry = 0\n",
        "        except Exception as e:\n",
        "            if cnt_retry == 1:\n",
        "                raise ValueError(e)\n",
        "            time.sleep(10)\n",
        "            cnt_retry -= 1\n",
        "\n",
        "    modified_code = re.findall(r\"```c(.*?)```\", result.content, re.DOTALL)[-1]\n",
        "    try_count = state.get('try_count', 0) + 1\n",
        "    os.makedirs(f'{PATH_FOR_RUNNING}/log-{LLM_MODEL_NAME_SPLIT}', exist_ok=True)\n",
        "    code_file_path = f\"{PATH_FOR_RUNNING}/log-{LLM_MODEL_NAME_SPLIT}/{state['code_file_path'].rsplit('/', 1)[-1][:-2].split('_', 1)[0]}_modified_code_try_{try_count}.c\" #f\"/kaggle/working/modified_code_try_{try_count}.c\"\n",
        "    write_specific_file(path=code_file_path, content=modified_code)\n",
        "    return {'code_file_path': code_file_path, 'try_count': try_count, 'generated_code': modified_code}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "NEWcYwZN3m31",
      "metadata": {
        "id": "NEWcYwZN3m31"
      },
      "outputs": [],
      "source": [
        "def log_to_file(filename, log_entry):\n",
        "    \"\"\"\n",
        "    Append a dictionary log entry to a file.\n",
        "\n",
        "    :param filename: Name of the file where the log should be written.\n",
        "    :param log_entry: Dictionary containing the log entry.\n",
        "    \"\"\"\n",
        "    with open(filename, 'a') as file:\n",
        "        json_entry = json.dumps(log_entry)\n",
        "        file.write(json_entry + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "b7389bab",
      "metadata": {
        "id": "b7389bab"
      },
      "outputs": [],
      "source": [
        "def check_exist_error(state):\n",
        "    code_have_error = state.get('code_have_error', False)\n",
        "    try_count = state.get('try_count', 0)\n",
        "    max_try_count =  state.get('max_try_count', 5)\n",
        "    if code_have_error and (try_count < max_try_count):\n",
        "        return {'next_node' : \"repair_faulty_code\"}\n",
        "    return {'next_node' : \"finish\"}\n",
        "\n",
        "def decide_next_node(state):\n",
        "    return state.get('next_node', \"finish\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "e1ab9ce9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1ab9ce9",
        "outputId": "44106bd8-9105-411f-e1b9-7bd4f21dedde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d35a9d69150>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow = StateGraph(GraphState)\n",
        "workflow.add_node(\"check_code_with_test_cases\", check_code_with_test_cases)\n",
        "workflow.add_node(\"repair_faulty_code\", repair_faulty_code)\n",
        "workflow.add_node(\"check_exist_error\", check_exist_error)\n",
        "\n",
        "workflow.add_edge(START, \"check_code_with_test_cases\")\n",
        "workflow.add_edge(\"check_code_with_test_cases\", \"check_exist_error\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"check_exist_error\",\n",
        "    decide_next_node,\n",
        "    {\n",
        "        \"repair_faulty_code\": \"repair_faulty_code\",\n",
        "        \"finish\": END\n",
        "    }\n",
        ")\n",
        "workflow.add_edge(\"repair_faulty_code\", \"check_code_with_test_cases\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "e63ef5e3",
      "metadata": {
        "id": "e63ef5e3"
      },
      "outputs": [],
      "source": [
        "if STORE_GRAPH_IN_MEMORY:\n",
        "    # The checkpointer lets the graph persist its state\n",
        "    # this is a complete memory for the entire graph.\n",
        "    memory = SqliteSaver.from_conn_string(\":memory:\")\n",
        "    graph = workflow.compile(checkpointer=memory)\n",
        "else:\n",
        "    graph = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "01cbd769",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "01cbd769",
        "outputId": "7490be27-6cd3-47c4-c8f2-7f261cd738be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "9061f892",
      "metadata": {
        "id": "9061f892"
      },
      "outputs": [],
      "source": [
        "import signal\n",
        "\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "def timeout_handler(signum, frame):\n",
        "    raise TimeoutException(\"Code execution exceeded the timeout limit\")\n",
        "\n",
        "def run_with_timeout(timeout, func, *args, **kwargs):\n",
        "    # Set the signal handler for the SIGALRM signal\n",
        "    signal.signal(signal.SIGALRM, timeout_handler)\n",
        "    # Set the alarm for the specified timeout\n",
        "    signal.alarm(timeout)\n",
        "    try:\n",
        "        # Execute the function with the provided arguments\n",
        "        result = func(*args, **kwargs)\n",
        "    except TimeoutException as e:\n",
        "        raise e\n",
        "    finally:\n",
        "        # Cancel the alarm\n",
        "        signal.alarm(0)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "571c9e39",
      "metadata": {
        "id": "571c9e39"
      },
      "outputs": [],
      "source": [
        "if RUN_ON_WINDOWS:\n",
        "    %pip install func_timeout\n",
        "\n",
        "    import time\n",
        "    from func_timeout import func_timeout, FunctionTimedOut\n",
        "\n",
        "\n",
        "    def deff():\n",
        "        import time\n",
        "        time.sleep(10)\n",
        "        return 'hi'\n",
        "\n",
        "    try:\n",
        "        result = func_timeout(5, deff, args=())\n",
        "        print(result)\n",
        "    except:\n",
        "        print(\"Code execution exceeded the timeout limit\")\n",
        "\n",
        "    def run_with_timeout_win(timeout, func, *args):\n",
        "        try:\n",
        "            # Execute the function with the provided arguments\n",
        "            result = func_timeout(timeout, func, args = (*args,))\n",
        "            return result\n",
        "        except:\n",
        "            raise TimeoutException(\"Code execution exceeded the timeout limit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "e2110033",
      "metadata": {
        "id": "e2110033"
      },
      "outputs": [],
      "source": [
        "COUNT_FIX_ERROR = 0\n",
        "COUNT_FAULTY_CODE = 0\n",
        "\n",
        "def log_to_file(filename, log_entry):\n",
        "    \"\"\"\n",
        "    Append a dictionary log entry to a file.\n",
        "\n",
        "    :param filename: Name of the file where the log should be written.\n",
        "    :param log_entry: Dictionary containing the log entry.\n",
        "    \"\"\"\n",
        "    with open(filename, 'a') as file:\n",
        "        json_entry = json.dumps(log_entry)\n",
        "        file.write(json_entry + '\\n')\n",
        "\n",
        "\n",
        "def find_and_store_paths(path):\n",
        "    # Store single or duplicated files (find input/output test_case)\n",
        "    dct_duplicated_file = collections.defaultdict(list)\n",
        "    for fl in glob.glob(f\"{path}/*\"):\n",
        "        tmp_fl = re.sub(r'(input)|(output)', '', fl)\n",
        "        if tmp_fl in dct_duplicated_file['unique_files']:\n",
        "            dct_duplicated_file['unique_files'].remove(tmp_fl)\n",
        "            dct_duplicated_file['duplicate_files'].append(fl)\n",
        "            fl = re.sub(r'\\b(input|output)\\b', lambda x: 'output' if x.group() == 'input' else 'input', fl)\n",
        "            dct_duplicated_file['duplicate_files'].append(fl)\n",
        "        elif not tmp_fl in dct_duplicated_file['unique_files']:\n",
        "            dct_duplicated_file['unique_files'].append(tmp_fl)\n",
        "    return dct_duplicated_file\n",
        "\n",
        "\n",
        "def graph_invoke_with_timeout(graph, inputs):\n",
        "    config_thread_id = {}\n",
        "    if STORE_GRAPH_IN_MEMORY:\n",
        "        thread_id = str(uuid.uuid4())\n",
        "        config_thread_id = {\"thread_id\": thread_id}\n",
        "    result = graph.invoke(inputs, config={**config_thread_id, \"recursion_limit\": 100})\n",
        "    return result\n",
        "\n",
        "def run_graph(graph, inputs):\n",
        "    global COUNT_FIX_ERROR\n",
        "    global COUNT_FAULTY_CODE\n",
        "    dct_log = {\n",
        "        'code_file_path' : (\n",
        "            \"/content/codeflaws\" + inputs['code_file_path'].split(\"codeflaws\")[-1]\n",
        "            if RUN_ON_WINDOWS\n",
        "            else inputs['code_file_path']\n",
        "        ),\n",
        "    }\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        if RUN_ON_WINDOWS:\n",
        "            result = run_with_timeout_win(60, graph_invoke_with_timeout, graph, inputs)\n",
        "        else:\n",
        "            result = run_with_timeout(600, graph_invoke_with_timeout, graph, inputs)\n",
        "        end_time = time.time()\n",
        "        dct_log = {\n",
        "            **dct_log,\n",
        "            'list_failed_test_cases_count': result['list_failed_test_cases_count'],\n",
        "            'apply_sbfl': result['apply_sbfl'],\n",
        "            'llm_model_name': inputs['llm_model_name'],\n",
        "            'initial_failed_test_cases_count': result['initial_failed_test_cases_count'],\n",
        "            'fail_test_cases': len(result['fail_test_cases']),\n",
        "            'initial_code_have_error': result['initial_code_have_error'],\n",
        "            'code_have_error': result['code_have_error'],\n",
        "            'try_count': result['try_count'],\n",
        "            'response_time': end_time - start_time,\n",
        "            'generated_code': result.get('generated_code', ''),\n",
        "            'log_execution': '\\n'.join(result['log_execution']),\n",
        "        }\n",
        "        COUNT_FIX_ERROR += (result['try_count']>0) and (result['code_have_error']==False)\n",
        "        COUNT_FAULTY_CODE += (result['try_count']>0)\n",
        "    except Exception as e:\n",
        "        dct_log = {\n",
        "            **dct_log,\n",
        "            'error': repr(e),\n",
        "        }\n",
        "        # The below line checks if the open-router API is not reachable, so we need to write it to the log file.\n",
        "        if \"'NoneType' object is not iterable\" in dct_log.get('error', \"\"):\n",
        "            print(\"open-router API is not reachable\")\n",
        "            return\n",
        "    LLM_MODEL_NAME = inputs['llm_model_name']\n",
        "    LLM_MODEL_NAME_SPLIT = LLM_MODEL_NAME.split('/')[-1] + (\"-wo-testcases-exec\" if WITHOUT_TESTCASES_EXEC else \"\")\n",
        "    log_to_file(f\"{PATH_FOR_RUNNING}/logfile-{LLM_MODEL_NAME_SPLIT}.txt\", dct_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "7dTsssc6s3Zc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "7dTsssc6s3Zc",
        "outputId": "9ecccb1a-3d01-4ff4-9c8d-594ba2bba34a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/3908 [01:16<83:06:47, 76.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "open-router-llama-3.1-70b-instruct:free-wo-testcases-exec\n",
            "2\n",
            "/content/codeflaws/14-B-bug-9606134-9606175/14-B-9606134.c\n",
            "Try 3, With meta-llama/llama-3.1-70b-instruct:free, By api_keys_1\n",
            "api_keys_1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/3908 [01:24<91:51:44, 84.64s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-fab8fb826439>\u001b[0m in \u001b[0;36mrepair_faulty_code\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'messages'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;31m# Because we don't get an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3028\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 results.append(\n\u001b[0;32m--> 691\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    692\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    927\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         }\n\u001b[0;32m--> 476\u001b[0;31m         response = self.completion_with_retry(\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_openai_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-93ba86e06e5d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m                             \u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                         }\n\u001b[0;32m---> 59\u001b[0;31m                         \u001b[0mrun_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{(COUNT_FIX_ERROR / COUNT_FAULTY_CODE)*100} %\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-282ac80a1af8>\u001b[0m in \u001b[0;36mrun_graph\u001b[0;34m(graph, inputs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_with_timeout_win\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_invoke_with_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_with_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_invoke_with_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         dct_log = {\n",
            "\u001b[0;32m<ipython-input-54-7c2bebf4e209>\u001b[0m in \u001b[0;36mrun_with_timeout\u001b[0;34m(timeout, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Execute the function with the provided arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-282ac80a1af8>\u001b[0m in \u001b[0;36mgraph_invoke_with_timeout\u001b[0;34m(graph, inputs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mthread_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mconfig_thread_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"thread_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthread_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_thread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recursion_limit\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2367\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2368\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 )\n\u001b[1;32m    545\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-fab8fb826439>\u001b[0m in \u001b[0;36mrepair_faulty_code\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcnt_retry\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mcnt_retry\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "    for folder in tqdm.tqdm(glob.glob(\n",
        "        \"/content/codeflaws/*\"\n",
        "    )):\n",
        "        for LLM_MODEL_NAME in [\n",
        "            \"meta-llama/open-router-llama-3.1-70b-instruct:free\",\n",
        "            \"meta-llama/open-router-llama-3.1-405b-instruct:free\",\n",
        "            \"meta-llama/open-router-llama-3.2-90b-vision-instruct:free\",\n",
        "        ]:\n",
        "\n",
        "            LLM_MODEL_NAME_SPLIT = LLM_MODEL_NAME.split('/')[-1] + (\"-wo-testcases-exec\" if WITHOUT_TESTCASES_EXEC else \"\")\n",
        "            before_ask_files = []\n",
        "            try:\n",
        "                if CHECK_BEFORE_ASK:\n",
        "                    file_path = f'{PATH_FOR_RUNNING}/logfile-{LLM_MODEL_NAME_SPLIT}.txt'\n",
        "                    with open(file_path, 'r') as file:\n",
        "                        for line in file:\n",
        "                            line = line.strip()\n",
        "                            try:\n",
        "                                dictionary = json.loads(line)\n",
        "                                if isinstance(dictionary, dict):  # Ensure it's actually a dictionary\n",
        "                                    before_ask_files.append(dictionary['code_file_path'])\n",
        "                            except (ValueError, SyntaxError) as e:\n",
        "                                pass\n",
        "            except:\n",
        "                pass\n",
        "            print(LLM_MODEL_NAME_SPLIT)\n",
        "            print(len(before_ask_files))\n",
        "\n",
        "\n",
        "            global COUNT_FIX_ERROR\n",
        "            global COUNT_FAULTY_CODE\n",
        "            dct_paths = find_and_store_paths(path=folder)\n",
        "            # Get code_file and compile. Input test case and get result\n",
        "            for fl_path in dct_paths['unique_files']:\n",
        "                fl_path_win2colab = \"\"\n",
        "                if RUN_ON_WINDOWS:\n",
        "                    fl_path = '/'.join(fl_path.split('\\\\'))\n",
        "                    fl_path_win2colab = \"/content/codeflaws\" + fl_path.split(\"codeflaws\")[-1]\n",
        "                if (fl_path.endswith('.c') and\n",
        "                    (\n",
        "                        fl_path not in before_ask_files and\n",
        "                        fl_path_win2colab not in before_ask_files\n",
        "                    )\n",
        "                ):\n",
        "                        print(fl_path)\n",
        "                        inputs = {\n",
        "                            \"list_failed_test_cases_count\": [],\n",
        "                            \"llm_model_name\": LLM_MODEL_NAME,\n",
        "                            \"code_file_path\": fl_path,\n",
        "                            \"test_case_paths\": dct_paths[\"duplicate_files\"],\n",
        "                            \"apply_sbfl\": APPLY_SBFL,\n",
        "                            \"sbfl_formula\": \"Ochiai\",\n",
        "                            \"sbfl_likelihood\": 0.5,\n",
        "                            \"max_try_count\": 2,\n",
        "                            \"try_count\": 0,\n",
        "                            \"messages\": []\n",
        "                        }\n",
        "                        run_graph(graph, inputs)\n",
        "            try:\n",
        "                print(f\"{(COUNT_FIX_ERROR / COUNT_FAULTY_CODE)*100} %\")\n",
        "            except:\n",
        "                pass\n",
        "            if not COUNT_FAULTY_CODE % 10:\n",
        "                clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pRA2NNcvQJNS",
      "metadata": {
        "id": "pRA2NNcvQJNS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "14d984a9"
      ],
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 188353168,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30746,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 37276.805327,
      "end_time": "2024-08-04T06:35:33.752116",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-08-03T20:14:16.946789",
      "version": "2.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
